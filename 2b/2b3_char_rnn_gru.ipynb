{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2b3_char_rnn_gru.ipynb","provenance":[],"collapsed_sections":["-WEDZ53Zbu0h","VcDJZphiU4ec"],"authorship_tag":"ABX9TyOhLU3HVwYbG3r0tGvph9vU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-WEDZ53Zbu0h"},"source":["# Question 2b3\n","Design a Character RNN Classifier that receives character ids and classify the input. The RNN is GRU layer and has a hidden-layer size of 20.\n","\n","Plot the entropy cost on training data and the accuracy on testing data against training epochs."]},{"cell_type":"markdown","metadata":{"id":"L5pxx5f-Uskg"},"source":["# Imports and Setup"]},{"cell_type":"code","metadata":{"id":"HdVcgqJuT-r1","executionInfo":{"status":"ok","timestamp":1605194164773,"user_tz":-480,"elapsed":37425,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}},"outputId":"a10c12bf-c597-4141-e994-b0b212c2ad85","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)\n","\n","# chuanxin\n","%cd \"../gdrive/My Drive/cz4042_assignment_2/2b\" "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n","/gdrive/My Drive/cz4042_assignment_2/2b\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XYLMIZfUUu19","executionInfo":{"status":"ok","timestamp":1605194167264,"user_tz":-480,"elapsed":39912,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["import os\n","import time\n","import json\n","import csv\n","import re\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import numpy as np\n","import tensorflow as tf"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"EWdh-qfGWLb1","executionInfo":{"status":"ok","timestamp":1605194167265,"user_tz":-480,"elapsed":39911,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["seed = 10\n","np.random.seed(seed)\n","tf.random.set_seed(seed)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VcDJZphiU4ec"},"source":["# Helper functions"]},{"cell_type":"markdown","metadata":{"id":"upXJ-u4cU8gY"},"source":["### read_data_chars()\n","Used to load in the data. Returns x_train, y_train, x_test, y_test"]},{"cell_type":"code","metadata":{"id":"cBuzMdbSU3em","executionInfo":{"status":"ok","timestamp":1605194167265,"user_tz":-480,"elapsed":39907,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["def read_data_chars():\n","    x_train, y_train, x_test, y_test = [], [], [], []\n","    cop = re.compile(\"[^a-z^A-Z^0-9^,^.^' ']\")\n","    with open('./train_medium.csv', encoding='utf-8') as filex:\n","        reader = csv.reader(filex)\n","        for row in reader:\n","            data = cop.sub(\"\", row[1])\n","            x_train.append(data)\n","            y_train.append(int(row[0]))\n","\n","    with open('./test_medium.csv', encoding='utf-8') as filex:\n","        reader = csv.reader(filex)\n","        for row in reader:\n","            data = cop.sub(\"\", row[1])\n","            x_test.append(data)\n","            y_test.append(int(row[0]))\n","\n","\n","    vocab_size, char_to_ix = vocabulary(x_train+x_test)\n","    x_train = preprocess(x_train, char_to_ix, MAX_DOCUMENT_LENGTH)\n","    y_train = np.array(y_train)\n","    x_test = preprocess(x_test, char_to_ix, MAX_DOCUMENT_LENGTH)\n","    y_test = np.array(y_test)\n","\n","    x_train = tf.constant(x_train, dtype=tf.int64)\n","    y_train = tf.constant(y_train, dtype=tf.int64)\n","    x_test = tf.constant(x_test, dtype=tf.int64)\n","    y_test = tf.constant(y_test, dtype=tf.int64)\n","\n","    return x_train, y_train, x_test, y_test"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lw4xNc4tb9mh"},"source":["### vocabulary(strings)\n","Read data with [character]. Get the unique characters in this strings and the vocab size (of characters)"]},{"cell_type":"code","metadata":{"id":"2x7REe4-cBQA","executionInfo":{"status":"ok","timestamp":1605194167266,"user_tz":-480,"elapsed":39904,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["def vocabulary(strings):\n","    chars = sorted(list(set(list(''.join(strings)))))\n","    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n","    vocab_size = len(chars)\n","    return vocab_size, char_to_ix"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"af_uf97ecZ8M"},"source":["### preprocess(strings, char_to_ix, MAX_LENGTH)\n","Clean up a string "]},{"cell_type":"code","metadata":{"id":"E1gJ4CxYcZp5","executionInfo":{"status":"ok","timestamp":1605194167266,"user_tz":-480,"elapsed":39902,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["def preprocess(strings, char_to_ix, MAX_LENGTH):\n","    data_chars = [list(d.lower()) for _, d in enumerate(strings)]\n","    for i, d in enumerate(data_chars):\n","        if len(d)>MAX_LENGTH:\n","            d = d[:MAX_LENGTH]\n","        elif len(d) < MAX_LENGTH:\n","            d += [' '] * (MAX_LENGTH - len(d))\n","            \n","    data_ids = np.zeros([len(data_chars), MAX_LENGTH], dtype=np.int64)\n","    for i in range(len(data_chars)):\n","        for j in range(MAX_LENGTH):\n","            data_ids[i, j] = char_to_ix[data_chars[i][j]]\n","    return np.array(data_ids)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p7NvMFU2KZCc"},"source":["### make_directories()\n","Used to create directories that might not have been made"]},{"cell_type":"code","metadata":{"id":"xl440MwmKY4C","executionInfo":{"status":"ok","timestamp":1605194167267,"user_tz":-480,"elapsed":39901,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["# Create folder to store histories and figures\n","def make_directories():\n","  if not os.path.exists('./histories'):\n","    os.mkdir('./histories')\n","  if not os.path.exists('./figures'):\n","    os.mkdir('./figures')"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rAbBYp9iKJ6R"},"source":["### history_saver(history, filename, already_json=False)\n","Used to save a history object"]},{"cell_type":"code","metadata":{"id":"Hp6cbjJhKJnS","executionInfo":{"status":"ok","timestamp":1605194167267,"user_tz":-480,"elapsed":39899,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["# filename like 'history/model_name.json'\n","def history_saver(history, model_name, already_json=False):\n","  history_json = {}\n","\n","  if already_json:\n","    history_json = history\n","  else:\n","    history = history.history\n","    for key in history.keys():\n","      history_json[key] = history[key]\n","\n","  with open('./histories/' + model_name, 'w') as file:\n","    json.dump(history_json, file)\n","\n","  print(\"History saved\")"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-zCk874hLSKK"},"source":["### history_loader(filename)\n","Used to load in a json history object"]},{"cell_type":"code","metadata":{"id":"yqCAHrE4LShy","executionInfo":{"status":"ok","timestamp":1605194167267,"user_tz":-480,"elapsed":39897,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["# filename like 'history/model_name.json'\n","def history_loader(model_name):\n","  with open('./histories/'+model_name) as json_file:\n","    history = json.load(json_file)\n","  print('History loaded')\n","  \n","  return history "],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n_URv4UfQoGr"},"source":["### plot_loss(history_json, model_name)\n","Plot out loss graph, and also save it"]},{"cell_type":"code","metadata":{"id":"9ERB0N0cQodE","executionInfo":{"status":"ok","timestamp":1605194167268,"user_tz":-480,"elapsed":39896,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["def plot_loss(history_json, model_name):\n","  train_loss = history_json['loss']\n","  test_loss = history_json['test_loss']\n","  title = 'Model name: ' + model_name + '\\nloss against epochs'\n","\n","  plt.plot(train_loss, label='train')\n","  plt.plot(test_loss, label='test')\n","  plt.title(title)\n","  plt.ylabel('loss')\n","  plt.xlabel('epochs')\n","  plt.legend()\n","  plt.savefig(f'./figures/{model_name}_loss.png')\n","  \n","  plt.show()"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"69De_d4XQuBZ"},"source":["### plot_acc(history_json, model_name)\n","Plot out accuracy graph, and also save it"]},{"cell_type":"code","metadata":{"id":"lU9d-fF5QuW1","executionInfo":{"status":"ok","timestamp":1605194167268,"user_tz":-480,"elapsed":39894,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["def plot_acc(history_json, model_name):\n","  train_acc = history_json['accuracy']\n","  test_acc = history_json['test_accuracy']\n","  title = 'Model name: ' + model_name + '\\naccuracy against epochs'\n","\n","  plt.plot(train_acc, label='train')\n","  plt.plot(test_acc, label='test')\n","  plt.title(title)\n","  plt.ylabel('accuracy')\n","  plt.xlabel('epochs')\n","  plt.legend()\n","  plt.savefig(f'./figures/{model_name}_accuracy.png')\n","  \n","  plt.show()"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LDvlc9ZbWhZl"},"source":["# 2b3 - CharRNN (GRU)"]},{"cell_type":"code","metadata":{"id":"z1U1trQWVDuG","executionInfo":{"status":"ok","timestamp":1605194167269,"user_tz":-480,"elapsed":39893,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["tf.keras.backend.set_floatx('float32')\n","class CharRNN(tf.keras.Model):\n","  def __init__(self, vocab_size, use_dropout, hidden_dims, rnn_type, num_rnn_layers):\n","    super(CharRNN, self).__init__()\n","    self.vocab_size = vocab_size\n","    self.use_dropout = use_dropout\n","\n","    # Weight variables and RNN cell\n","    self.hidden_dims = hidden_dims\n","    self.rnn_type = rnn_type\n","    self.num_rnn_layers = num_rnn_layers\n","\n","    if self.rnn_type == 'GRU' and self.num_rnn_layers == 1:\n","      self.rnn1 = tf.keras.layers.RNN(tf.keras.layers.GRUCell(self.hidden_dims), unroll=True)\n","    elif self.rnn_type == 'GRU' and self.num_rnn_layers == 2:\n","      self.rnn1 = tf.keras.layers.RNN(tf.keras.layers.GRUCell(self.hidden_dims), unroll=True, return_sequences=True)\n","      self.rnn2 = tf.keras.layers.RNN(tf.keras.layers.GRUCell(self.hidden_dims), unroll=True)\n","    elif self.rnn_type == 'SimpleRNN' and self.num_rnn_layers == 1:\n","      self.rnn1 = tf.keras.layers.RNN(tf.keras.layers.SimpleRNNCell(self.hidden_dims), unroll=True)     \n","    elif self.rnn_type == 'SimpleRNN' and self.num_rnn_layers == 2:\n","      self.rnn1 = tf.keras.layers.RNN(tf.keras.layers.SimpleRNNCell(self.hidden_dims), unroll=True, return_sequences=True)\n","      self.rnn2 = tf.keras.layers.RNN(tf.keras.layers.SimpleRNNCell(self.hidden_dims), unroll=True)     \n","    elif self.rnn_type == 'LSTM' and self.num_rnn_layers == 1:\n","      self.rnn1 = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(self.hidden_dims), unroll=True)\n","    elif self.rnn_type == 'LSTM' and self.num_rnn_layers == 2:\n","      self.rnn1 = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(self.hidden_dims), unroll=True, return_sequences=True)\n","      self.rnn2 = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(self.hidden_dims), unroll=True)\n","    else:\n","      print(\"wrong input\")   \n","\n","    self.dense = tf.keras.layers.Dense(MAX_LABEL, activation=None)\n","\n","  def call(self, x, drop_rate):\n","    # forward\n","    x = tf.one_hot(x, one_hot_size)\n","    encoding = self.rnn1(x)\n","    if self.num_rnn_layers == 2:\n","      encoding = self.rnn2(encoding)\n","    if self.use_dropout:\n","      encoding = tf.nn.dropout(encoding, drop_rate)\n","    logits = self.dense(encoding)\n","    return logits"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"bOf6Fd5rueTA","executionInfo":{"status":"ok","timestamp":1605194167269,"user_tz":-480,"elapsed":39891,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["# Training function\n","def train_step(model, x, label, optimizer, drop_rate):\n","  with tf.GradientTape() as tape:\n","    out = model(x, drop_rate)\n","    loss = loss_object(label, out)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","      \n","  train_loss(loss)\n","  train_accuracy(label, out)\n","\n","# Testing function\n","def test_step(model, x, label, drop_rate):\n","  out = model(x,drop_rate)\n","  t_loss = loss_object(label, out)\n","  test_loss(t_loss)\n","  test_accuracy(label, out)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"9tl4IUM5uhlx","executionInfo":{"status":"ok","timestamp":1605194167270,"user_tz":-480,"elapsed":39890,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["def fit(model):\n","  train_acc_list, train_loss_list, test_acc_list, test_loss_list = [], [], [], []\n","  time_start = time.perf_counter()\n","\n","  for epoch in range(no_epochs):\n","    # Reset the metrics at the start of the next epoch\n","    train_accuracy.reset_states()\n","    train_loss.reset_states()\n","    test_accuracy.reset_states()\n","    test_loss.reset_states()\n","\n","    for images, labels in train_ds:\n","      train_step(model, images, labels, optimizer, 0.5)\n","\n","    for images, labels in test_ds:\n","      test_step(model, images, labels, 0)\n","\n","    \n","    train_acc_list.append(train_accuracy.result())\n","    train_loss_list.append(train_loss.result())\n","    test_acc_list.append(test_accuracy.result())\n","    test_loss_list.append(test_loss.result())\n","\n","    template = 'Epoch {}, train_accuracy: {}, train_loss: {}, test_accuracy: {}, test_loss: {}'\n","    print (template.format(epoch+1,\n","                          train_accuracy.result(),\n","                          train_loss.result(),\n","                          test_accuracy.result(),\n","                          test_loss.result()))\n","\n","  time_stop = time.perf_counter()\n","  time_taken = time_stop-time_start\n","\n","  return train_acc_list, train_loss_list, test_acc_list, test_loss_list, time_taken"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bCH46KpPx1Wu"},"source":["### Parameters"]},{"cell_type":"code","metadata":{"id":"9lUtvHlHuUTT","executionInfo":{"status":"ok","timestamp":1605194167270,"user_tz":-480,"elapsed":39889,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["MAX_DOCUMENT_LENGTH = 100\n","HIDDEN_SIZE = 20\n","RNN_TYPE = 'GRU'\n","NUM_RNN_LAYERS = 1\n","MAX_LABEL = 15\n","\n","batch_size = 128\n","one_hot_size = 256\n","no_epochs = 250\n","lr = 0.01"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"T9LTnMMI1IUd","executionInfo":{"status":"ok","timestamp":1605194172807,"user_tz":-480,"elapsed":45424,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["# Choose optimizer and loss function for training\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n","\n","# Select metrics to measure the loss and the accuracy of the model. \n","# These metrics accumulate the values over epochs and then print the overall result.\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GW3ZGh2c2wyZ","executionInfo":{"status":"ok","timestamp":1605194174296,"user_tz":-480,"elapsed":46911,"user":{"displayName":"Chuan Xin Tan","photoUrl":"","userId":"02973160042406904249"}}},"source":["# Training and test\n","make_directories()\n","x_train, y_train, x_test, y_test = read_data_chars()\n","\n","# Use `tf.data` to batch and shuffle the dataset:\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEagapWE0uz_","outputId":"b9319579-c8cf-4b38-c233-316b36a1b8a7","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = CharRNN(256, False, HIDDEN_SIZE, RNN_TYPE, NUM_RNN_LAYERS)\n","model_name = 'q3_char_rnn_gru'\n","train_acc_list, train_loss_list, test_acc_list, test_loss_list, time_taken = fit(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1, train_accuracy: 0.06303571164608002, train_loss: 2.705968141555786, test_accuracy: 0.07857143133878708, test_loss: 2.6991474628448486\n","Epoch 2, train_accuracy: 0.06624999642372131, train_loss: 2.7011468410491943, test_accuracy: 0.08142857253551483, test_loss: 2.6948394775390625\n","Epoch 3, train_accuracy: 0.06875000149011612, train_loss: 2.697040319442749, test_accuracy: 0.08428571373224258, test_loss: 2.691061019897461\n","Epoch 4, train_accuracy: 0.0714285746216774, train_loss: 2.693399667739868, test_accuracy: 0.07999999821186066, test_loss: 2.687709093093872\n","Epoch 5, train_accuracy: 0.07357142865657806, train_loss: 2.6901025772094727, test_accuracy: 0.08285713940858841, test_loss: 2.6846916675567627\n","Epoch 6, train_accuracy: 0.07392857223749161, train_loss: 2.687150716781616, test_accuracy: 0.07999999821186066, test_loss: 2.6819522380828857\n","Epoch 7, train_accuracy: 0.07571428269147873, train_loss: 2.6845450401306152, test_accuracy: 0.07857143133878708, test_loss: 2.679435968399048\n","Epoch 8, train_accuracy: 0.07482142746448517, train_loss: 2.6819698810577393, test_accuracy: 0.07857143133878708, test_loss: 2.677122116088867\n","Epoch 9, train_accuracy: 0.07517857104539871, train_loss: 2.679774522781372, test_accuracy: 0.0771428570151329, test_loss: 2.6749699115753174\n","Epoch 10, train_accuracy: 0.07517857104539871, train_loss: 2.677633285522461, test_accuracy: 0.0771428570151329, test_loss: 2.672975778579712\n","Epoch 11, train_accuracy: 0.07553571462631226, train_loss: 2.6757264137268066, test_accuracy: 0.07857143133878708, test_loss: 2.6711063385009766\n","Epoch 12, train_accuracy: 0.0758928582072258, train_loss: 2.673839569091797, test_accuracy: 0.07571428269147873, test_loss: 2.6693496704101562\n","Epoch 13, train_accuracy: 0.07339286059141159, train_loss: 2.672107458114624, test_accuracy: 0.0771428570151329, test_loss: 2.6676957607269287\n","Epoch 14, train_accuracy: 0.07625000178813934, train_loss: 2.6705129146575928, test_accuracy: 0.07857143133878708, test_loss: 2.666128396987915\n","Epoch 15, train_accuracy: 0.07357142865657806, train_loss: 2.668980598449707, test_accuracy: 0.07999999821186066, test_loss: 2.6646480560302734\n","Epoch 16, train_accuracy: 0.07553571462631226, train_loss: 2.6675031185150146, test_accuracy: 0.07999999821186066, test_loss: 2.6632471084594727\n","Epoch 17, train_accuracy: 0.0746428593993187, train_loss: 2.666149139404297, test_accuracy: 0.07999999821186066, test_loss: 2.661909341812134\n","Epoch 18, train_accuracy: 0.07482142746448517, train_loss: 2.664839506149292, test_accuracy: 0.08142857253551483, test_loss: 2.66064453125\n","Epoch 19, train_accuracy: 0.07535714656114578, train_loss: 2.663588285446167, test_accuracy: 0.07999999821186066, test_loss: 2.659442186355591\n","Epoch 20, train_accuracy: 0.07517857104539871, train_loss: 2.6623048782348633, test_accuracy: 0.07857143133878708, test_loss: 2.6582839488983154\n","Epoch 21, train_accuracy: 0.07660714536905289, train_loss: 2.6612112522125244, test_accuracy: 0.08285713940858841, test_loss: 2.6571853160858154\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YXPSuKJl5ZAt"},"source":["for metric_list in [train_acc_list, train_loss_list, test_acc_list, test_loss_list]:\n","  metric_list[:] = [x.numpy() for x in metric_list]\n","  metric_list[:] = [x.astype(float) for x in metric_list]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLPeXFWA10P6"},"source":["history_json = {model_name: {\n","    'accuracy': train_acc_list,\n","    'test_accuracy': test_acc_list,\n","    'loss': train_loss_list,\n","    'test_loss': test_loss_list,\n","    'time_taken': time_taken\n","}}\n","\n","history_saver(history_json, model_name, already_json=True)\n","histories_json = history_loader(model_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUr2r3jh11Ak"},"source":["plot_acc(histories_json[model_name], model_name)\n","plot_loss(histories_json[model_name], model_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ogOPrzW4VgGb"},"source":["histories_json[model_name]['time_taken']"],"execution_count":null,"outputs":[]}]}